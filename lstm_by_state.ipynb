{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.6\n",
      "IPython 7.13.0\n",
      "\n",
      "numpy 1.18.1\n",
      "pandas 0.23.4\n",
      "torch 1.4.0\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os, wget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.lstm_torch import LSTM_Predictor, set_seq, train_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 10\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11be576b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('time_series_19-covid-Deaths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/us-states.json', 'r') as f:\n",
    "    us_states = json.load(f)\n",
    "    \n",
    "state_abrs = [x['id'] for x in us_states['features']]\n",
    "\n",
    "state_mapper_lst = [{x['properties']['name']:x['id']} for x in us_states['features']]\n",
    "\n",
    "state_mapper_lst\n",
    "state_mapper = {}\n",
    "for s in state_mapper_lst:\n",
    "    state_mapper.update(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_to_abr(name, mapping_dict):\n",
    "    return mapping_dict[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = confirmed_melted['Country/Region'].str.contains('US')\n",
    "df_US = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_data_loader():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 region_abr = None: str, \n",
    "                 region_list = None, \n",
    "                 state_mapper = None, \n",
    "                 country: str, \n",
    "                 df,\n",
    "                 model,\n",
    "                 test_data_size=0):\n",
    "        \n",
    "        self.df = df\n",
    "        self.state_abr = state_abr\n",
    "        self.country = country\n",
    "        self.region_list = region_list\n",
    "        self.state_mapper = state_mapper\n",
    "        self.test_data_size = 0\n",
    "        self.model = model\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.sequence_length = 5\n",
    "        \n",
    "    def _remap_to_abr(self):\n",
    "        return self.state_mapper[self.state_abr]\n",
    "        \n",
    "    def subset_df(self, \n",
    "                  df=self.df, \n",
    "                  region_list=self.region_list,\n",
    "                  state_mapper=self.state_mapper):\n",
    "        \n",
    "        if self.state_abr:\n",
    "            \n",
    "            mask1 = self.df['Country/Region'].str.contains(self.country)\n",
    "            self.df = self.df[mask1]\n",
    "            \n",
    "            for x in region_list:\n",
    "                counter = 0\n",
    "                for r in self.df[['Province/State','Confirmed']]\n",
    "                    if x in r:\n",
    "                        self.df['Province/State'].iloc[counter] = x\n",
    "                    elif r in state_mapper.keys():\n",
    "                        self.df['Province/State'].iloc[counter] = self.remap()\n",
    "                    counter += 0\n",
    "                        \n",
    "            mask2 = df['Province/State'].str.contains(self.state_abr)\n",
    "            self.df = df[mask1 & mask2]\n",
    "            self.df = self.df.groupby('Province/State').sum().reset_index()\n",
    "                \n",
    "        else:\n",
    "            mask1 = df['Country/Region'].str.contains(self.country)\n",
    "            self.df = df[mask1]\n",
    "            self.df = self.df.groupby('Country/Region')\n",
    "            \n",
    "    def transform_df_datetime(self, df=self.df):\n",
    "        df = df.sum(axis=0)\n",
    "        df.index = pd.to_datetime(self.df.index)\n",
    "        \n",
    "    def gen_data_sets(self,test_data_size=self.test_data_size):   \n",
    "        self.train_data = self.df[:-test_data_size]\n",
    "        self.train_data = self.scaler.transform(np.expand_dims(self.train_data, axis=1))\n",
    "\n",
    "        if self.test_data_size:\n",
    "            self.test_data = self.df[-test_data_size:]\n",
    "            self.test_data = self.scaler.transform(np.expand_dims(self.test_data, axis=1))\n",
    "        \n",
    "    def set_seq(d, seq_len = self.sequence_length):\n",
    "        xi = []\n",
    "        yi = []\n",
    "\n",
    "        for i in range(len(d) - seq_len):\n",
    "            x = d[i:(i+seq_len)]\n",
    "            y = d[i:(i+seq_len)]\n",
    "            xi.append(x)\n",
    "            yi.append(y)\n",
    "\n",
    "        out_arrs = np.array(xi), np.array(yi)\n",
    "        return out_arrs \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = confirmed_melted['Date'].str.contains(first_day)\n",
    "mask2 = confirmed_melted['Country/Region'].str.contains('US')\n",
    "first_day_df_US = confirmed_melted[mask1 & mask2]\n",
    "first_day_df_US.head()\n",
    "\n",
    "first_day_df_US = first_day_df_US[['Province/State','Confirmed']]\n",
    "\n",
    "for x in state_abrs:\n",
    "    counter=0\n",
    "    for r in first_day_df_US['Province/State']:\n",
    "        if x in r:\n",
    "            first_day_df_US['Province/State'].iloc[counter] = x\n",
    "        elif r in state_mapper.keys():\n",
    "            first_day_df_US['Province/State'].iloc[counter] = remap_to_abr(r, state_mapper)\n",
    "        counter+=1\n",
    "        \n",
    "\n",
    "first_day_df_US = first_day_df_US.groupby('Province/State').sum().reset_index()\n",
    "first_day_df_US.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = confirmed_melted['Country/Region'].str.contains('US')\n",
    "first_day_df_US = confirmed_melted[mask1 & mask2]\n",
    "first_day_df_US.head()\n",
    "\n",
    "first_day_df_US = first_day_df_US[['Province/State','Confirmed']]\n",
    "\n",
    "for x in state_abrs:\n",
    "    counter=0\n",
    "    for r in first_day_df_US['Province/State']:\n",
    "        if x in r:\n",
    "            first_day_df_US['Province/State'].iloc[counter] = x\n",
    "        elif r in state_mapper.keys():\n",
    "            first_day_df_US['Province/State'].iloc[counter] = remap_to_abr(r, state_mapper)\n",
    "        counter+=1\n",
    "        \n",
    "\n",
    "first_day_df_US = first_day_df_US.groupby('Province/State').sum().reset_index()\n",
    "first_day_df_US.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
